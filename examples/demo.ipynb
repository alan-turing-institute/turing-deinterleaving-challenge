{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turing Deinterleaving Challenge dataset walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please ensure all dependencies are installed correctly, a guide for how to do this can be found in README.md\n",
    "```bash\n",
    "pip list\n",
    "```\n",
    "should display ```turing-deinterleaving-challenge 0.1.0```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "* ` \n",
    "Deinterleaver` an abstract base class that your model **must comply with for evaluation.**\n",
    "* ```DeinterleavingchallengeDataset``` This class handles our radar pulse data. It handles loading and processing our data, supporting both **full length** pulse trains and **windowed sampling** through the ```window_length``` method. We can also filter/**control the number of emitters** in the dataset using the ```min_emitter, max_emitter``` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from turing_deinterleaving_challenge import (\n",
    "    Deinterleaver,\n",
    "    DeinterleavingChallengeDataset,\n",
    "    PulseTrain,\n",
    "    download_dataset,\n",
    "    evaluate_model_on_dataset,\n",
    "    plot_pulse_train,\n",
    "    plot_true_vs_predicted_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download data\n",
    "\n",
    "This cell **downloads the data from huggingface**, using the ```PulseTrain``` class' load method. We select which subset of the data (train/val/test) we want to download, n.b. there is a **separate private test set aside from the huggingface test subset.**\n",
    "\n",
    "We can then plot some examples of each PDW, with ```plot_pulse_train```. We can visualise these without and without labels with the ```plot_labels``` argument. Setting this to false, we can see **the extent of the deinterleaving problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_list = [\"train\", \"validation\", \"test\"]\n",
    "\n",
    "save_dir = Path(\"../data\")\n",
    "train_set_path = download_dataset(\n",
    "    save_dir=save_dir,\n",
    "    subsets=subset_list,\n",
    ")\n",
    "train_samples = list((Path(train_set_path) / subset_list[1]).glob(\"*.h5\"))\n",
    "for sample in train_samples[:3]:\n",
    "    train_sample = PulseTrain.load(sample)\n",
    "    plot_pulse_train(train_sample, plot_labels=True) \n",
    "    plot_pulse_train(train_sample, plot_labels=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process the data \n",
    "\n",
    "Next we can prepare our data for training/evaluation, processing the varying length pulse trains into (sub-)pulse trains of length 1000 using ```window_length = 1000```, filtering out any pulse trains with only one emitter using ```mix_emitters = 2```. \n",
    "\n",
    "In our challenge, we suggest using lengths of 1000, but we are very interested in solutions making interesting use of varying lengths. For example, what if a large model trained on very large window lengths generalises to short lengths at test time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DeinterleavingChallengeDataset(\n",
    "    subset=subset_list[1], window_length=1000, min_emitters=2\n",
    ") # recall subset_list[1] is \"validation\"\"\n",
    "print(f\"Processed dataset length: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define a DataLoader\n",
    "\n",
    "Load your ```dataset``` into a ```DataLoader``` as follows - shuffling if necessary and setting a batch size appropriate to your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define a deinterleaving model\n",
    "\n",
    "In our case, we skip training a model (that is the challenge!) defining a model which always predicts the same emitter for every pulse. \n",
    "\n",
    "This model inherits the abstract base class ```Deinterleaver```, which enforces that our model takes as input a batch of pulse trains, and outputs a batch sequences of emitter IDs (we need this for simple and equivalent scoring).\n",
    "\n",
    "Recall in the clustering problem, we're not actually trying to identify which specific emitter that a pulse came from (i.e., the value of the emitter index), just grouping pulses from the same emitter together - so a model always returning the predicted emitter index 1 is equivalent to a model always returning index 0, 2, 3, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClumpDeinterleaver(Deinterleaver):\n",
    "\n",
    "    def __call__(\n",
    "            self,\n",
    "            data # Float[Array, \"batch_size seq_len feature_len\"]\n",
    "        ):\n",
    "        return np.ones(data.shape[:2]) # Returning a one for every pulse train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate our model on the dataset\n",
    "\n",
    "We can now use the ```evaluate_model_on_dataset``` function to compute our performance metrics for our deinterleaving model.\n",
    "\n",
    " Unsurprisingly, always predicting that a pulse train came from the same single emitter gives a homogeneity of 0 and a completeness of 1. \n",
    "\n",
    "Remember - we are evaluating the model on the sub pulse trains, i.e., the windowed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = evaluate_model_on_dataset(\n",
    "    dataloader=dataloader,\n",
    "    model=ClumpDeinterleaver(),\n",
    ")\n",
    "for key, value in scores.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualise results\n",
    "\n",
    "We can now use our deinterleaver to make some (bad) predictions about what emitter a given pulse belongs to, visualising the results against the ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i, (data, labels) in enumerate(dataloader):\n",
    "    data = data.numpy()\n",
    "    prediction = ClumpDeinterleaver()(data)\n",
    "    predictions.append((data, prediction, labels.numpy()))\n",
    "    if i > 5:\n",
    "        break\n",
    "\n",
    "for data, prediction, labels in predictions:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plot_true_vs_predicted_features(\n",
    "        features=data[:2],\n",
    "        labels_pred=prediction,\n",
    "        labels_true=labels,\n",
    "        x_label=\"Time of Arrival (us)\",\n",
    "        y_label=\"Frequency (MHz)\",\n",
    "    )\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deinterleaving",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
